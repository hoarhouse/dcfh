<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Coexistence: Fraternity in the Age of AI - Domus Communis Foundation - DCF Hungary</title>
    <meta name="description" content="The choices we make today about AI will fundamentally shape the world we leave to future generations. AI is already causing significant harm: widening inequalities, concentrating power in the hands of a few, and damaging the environment.">
    <meta property="og:title" content="Coexistence: Fraternity in the Age of AI">
    <meta property="og:description" content="The choices we make today about AI will fundamentally shape the world we leave to future generations. AI is already causing significant harm: widening inequalities, concentrating power in the hands of a few, and damaging the environment.">
    <meta property="og:image" content="https://atzommnkkwzgbktuzjti.supabase.co/storage/v1/object/public/media/featured-media/featured_1759844249957.jpg">
    <meta property="og:type" content="article">
    <link rel="stylesheet" href="../../css/blog-post.css">
    <script src="https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2"></script>
    <script src="../../js/dcf-core.js"></script>
    <script src="../../js/dcf-ui.js"></script>
</head>
<body>
    <header class="header">
        <nav class="nav-container">
            <a href="../../index.html" class="logo"><!-- Logo dynamically generated by dcf-ui.js --></a>
            <ul class="nav-menu" id="navMenu">
                <!-- Populated by dcf-ui.js -->
            </ul>
            <div class="user-menu">
                <!-- Simple 4-button language switcher -->
                <div class="language-buttons">
                    <button onclick="changeLanguage('en')" class="lang-btn">EN</button>
                    <button onclick="changeLanguage('it')" class="lang-btn">IT</button>
                    <button onclick="changeLanguage('es')" class="lang-btn">ES</button>
                    <button onclick="changeLanguage('hu')" class="lang-btn">HU</button>
                </div>
            </div>
        </nav>
    </header>

    <nav class="breadcrumb">
        <div class="breadcrumb-container">
            <a href="../../index.html">Home</a>
            <span>‚Ä∫</span>
            <a href="../index.html">Blog</a>
            <span>‚Ä∫</span>
            <a href="../category.html?blog=domus-communis-foundation">Domus Communis Foundation</a>
            <span>‚Ä∫</span>
            <span>Coexistence: Fraternity in the Age of AI</span>
        </div>
    </nav>

    <main class="main-container">
        <article>
            <div class="post-header">
                <div class="post-featured-media"><img src="https://atzommnkkwzgbktuzjti.supabase.co/storage/v1/object/public/media/featured-media/featured_1759844249957.jpg" alt="Coexistence: Fraternity in the Age of AI"></div>
                <div class="post-header-content">
                    <div class="post-meta">
                        <span>2025-10-07</span>
                        <span>Domus Communis Foundation</span>
                        <span id="viewCount">6 views</span>
                    </div>
                    <h1 class="post-title">Coexistence: Fraternity in the Age of AI</h1>
                    <div class="post-excerpt">The choices we make today about AI will fundamentally shape the world we leave to future generations. AI is already causing significant harm: widening inequalities, concentrating power in the hands of a few, and damaging the environment.</div>
                </div>
            </div>

            <div class="post-content">
                <div class="post-body">
                    <p><strong><em>Our global appeal for peaceful human coexistence and shared responsibility</em></strong></p><p><strong>Rome, September 12, 2025</strong></p><p><br></p><p><strong>To:</strong></p><ul><li>His Holiness Pope Leo XIV</li><li>All Global Leaders</li><li>All People of Good Will</li></ul><p><em>(English version ‚Äî also available in </em><a href="https://hoarhouse.github.io/dcfh/public/dcf_ai_resource_view.html?slug=resource-1759841339531" rel="noopener noreferrer" target="_blank"><em>ar-AE</em></a><em>, de-DE, es-ES, fr-CA, fr-FR, he-IL, hi-IN, it-IT, ja-JP, ko-KR, pt-BR, sv-SE, zh-CN)</em></p><p><br></p><p><strong>Preamble</strong></p><p>Moved by a deep desire for a future where humans shape society and decisions, we‚Äîan independent roundtable composed of experts, technology leaders, thought leaders, and scholars from many different nations, backgrounds, and faiths‚Äîmake the following appeal for a future in which AI must be developed responsibly, by and for the people.</p><p>The choices we make today about AI will fundamentally shape the world we leave to future generations. AI is already causing significant harm: widening inequalities, concentrating power in the hands of a few, and damaging the environment. Vast and rapidly growing sums are being devoted to creating agentic technologies with the potential to surpass human intelligence‚Äîwhat many in the AI research community refer to as ‚Äúsuperintelligence.‚Äù These challenges call for moral leadership and urgent, concrete actions.</p><p>Artificial intelligence presents significant opportunities to advance scientific discovery and mutual human understanding, transform healthcare, improve governance, and foster sustainable, inclusive prosperity. However, it also poses serious risks‚Äîas described in the <em>International Scientific Report on AI Safety</em>‚Äîincluding job displacement, reduction of individual freedoms, power warfare, disinformation, manipulation, mass surveillance, environmental damage, and threats to human welfare.</p><p>To harness legitimate opportunities while mitigating risks, it is essential to establish foundations for human flourishing and clear boundaries rooted in dignity, community, human and environmental rights, and accountability.</p><p><br></p><p><strong>Our Appeal</strong></p><p>In a spirit of fraternity, hope, and caution, we call upon leadership worldwide to uphold the following principles and red lines, fostering dialogue and reflection on how AI can best serve our entire human family:</p><ol><li><strong>Human Life and Dignity</strong></li><li>AI must never be developed or used in ways that threaten, diminish, or disqualify human life, dignity, or fundamental rights. Human intelligence‚Äîour capacity for wisdom, moral reasoning, and orientation toward truth and beauty‚Äîmust never be devalued by artificial processing, however sophisticated.</li><li><strong>AI as a Tool, Not an Authority</strong></li><li>AI must remain under human control. Building uncontrollable systems or over-delegating decisions is morally unacceptable and must be legally prohibited. Development of ‚Äúsuperintelligent‚Äù AI technologies should not be allowed until there is broad scientific consensus that it can be done safely and controllably, with clear and broad public consent.</li><li><strong>Accountability</strong></li><li>Only humans have moral and legal agency. AI systems are and must remain legal <em>objects</em>, never <em>subjects</em>. Responsibility and liability rest with developers, vendors, companies, deployers, users, institutions, and governments. AI cannot be granted legal personhood or ‚Äúrights.‚Äù</li><li><strong>Life-and-Death Decisions</strong></li><li>AI must never be allowed to make life-or-death decisions‚Äîparticularly in military conflict, law enforcement, border control, healthcare, or judicial contexts.</li><li><strong>Safe and Ethical Development</strong></li><li>Developers must embed safety, transparency, and ethics into AI from the start. Deployers share equal responsibility. Independent testing and risk assessments must be mandatory before and throughout deployment.</li><li><strong>Stewardship</strong></li><li>Governments and corporations must never weaponize AI for domination, illegal wars of aggression, coercion, manipulation, social scoring, or mass surveillance.</li><li><strong>Responsible Design</strong></li><li>AI must be designed‚Äîand independently evaluated‚Äîto avoid unintentional or catastrophic effects on humans and society, such as deception, delusion, addiction, or loss of autonomy.</li><li><strong>No AI Monopoly</strong></li><li>The economic, medical, scientific, and social benefits of AI must not be monopolized by any group or nation.</li><li><strong>No Human Devaluation</strong></li><li>AI design and deployment should help humans flourish in their chosen pursuits, not render humanity redundant, disenfranchised, or replaceable.</li><li><strong>Ecological Responsibility</strong></li><li>AI development must not endanger the planet. Its large demands for energy, water, and rare minerals must be managed responsibly and sustainably across the entire supply chain.</li><li><strong>No Irresponsible Global Competition</strong></li><li>Nations and corporations must avoid reckless races toward ever more powerful AI systems.</li></ol><p><br></p><p><strong>Call to Action</strong></p><p>Upholding these principles demands moral courage, accountability, and farsighted leadership. We urge the creation of a <strong>binding international treaty</strong> establishing red lines and an <strong>independent oversight body</strong> with enforcement powers.</p><p>We call on:</p><ul><li><strong>Scientists, civil society, and rights groups</strong> to amplify public awareness of AI‚Äôs limitations and dangers.</li><li><strong>Industry and policymakers</strong> to center their work on protecting and benefiting the most vulnerable communities affected by AI‚Äôs material costs.</li><li><strong>Auditors and researchers</strong> to develop new metrics for evaluating AI‚Äîfocused on veracity, balance, and human good, not just performance or engagement.</li><li><strong>Governments and global communities</strong> to establish frameworks ensuring that AI governance serves the common good, including the right to live free from AI intrusion.</li></ul><p>The advancement of genuine human fraternity in the age of artificial intelligence requires <strong>universal ethical and legal standards.</strong></p><p>Finally, we appeal to all people of good will: let us unite to ensure that AI serves all humanity rather than a narrow few. By coming together across nations, cultures, and creeds‚Äîprioritizing dialogue over competition‚Äîwe can shape a future that uplifts human dignity and fosters a just and peaceful world.</p><p><br></p><p><strong>Working Group Members (Drafters of the Global Appeal)</strong></p><ol><li>Paolo Benanti <em>(Scientific Coordinator)</em></li><li>Yoshua Bengio</li><li>Ernesto Belisario</li><li>Abeba Birhane</li><li>Cornelius Boersch</li><li>Yuval Noah Harari</li><li>Geoffrey Hinton</li><li>Lorena Jaume-Palas√≠</li><li>Antal Kuthy</li><li>Riccardo Luna <em>(Coordinator)</em></li><li>Nnenna Nwakanma</li><li>Valerie Pisano</li><li>Stuart Russell</li><li>Max Tegmark</li><li>Marco Trombetti</li><li>Jimena Sof√≠a Viveros √Ålvarez</li><li>Alexander Waibel</li><li>will.i.am</li></ol><p><strong>Also signed by:</strong></p><ul><li>Miguel Benasayag</li><li>Giorgio Parisi</li><li>Maria Ressa</li></ul><p><br></p>
                </div>
            </div>

            <div class="post-footer">
                <div class="post-stats">
                    <span>Views: <strong id="footerViewCount">6</strong></span>
                    <span>Published: <strong>2025-10-07</strong></span>
                </div>
                <a href="../category.html?blog=domus-communis-foundation" class="back-to-blog">‚Üê Back to Blog</a>
            </div>
        </article>
    </main>

    <script>
        const postId = '8b023c05-136f-4280-9131-0beb0cb4ba77';
        
        // Initialize DCF UI when page loads
        window.addEventListener('load', function() {
            setTimeout(function() {
                if (window.dcfUI && typeof window.dcfUI.init === 'function') {
                    console.log('üöÄ Calling dcfUI.init()');
                    window.dcfUI.init();
                } else {
                    console.error('‚ùå dcfUI not available');
                }
            }, 200);
        });
        
        async function trackView() {
            if (!window.dcfSupabase) return;
            try {
                const { data: currentPost } = await window.dcfSupabase
                    .from('blog_posts')
                    .select('view_count')
                    .eq('id', postId)
                    .single();
                
                const newViewCount = (currentPost?.view_count || 0) + 1;
                
                await window.dcfSupabase
                    .from('blog_posts')
                    .update({ view_count: newViewCount })
                    .eq('id', postId);
                
                console.log('‚úÖ View tracked');
            } catch (err) {
                console.warn('View tracking error:', err);
            }
        }

        async function loadStats() {
            let attempts = 0;
            while (!window.dcfSupabase && attempts < 50) {
                await new Promise(r => setTimeout(r, 100));
                attempts++;
            }
            
            if (!window.dcfSupabase) return;
            
            try {
                const { data } = await window.dcfSupabase
                    .from('blog_posts')
                    .select('view_count')
                    .eq('id', postId)
                    .single();
                
                if (data) {
                    document.getElementById('viewCount').textContent = `${data.view_count || 0} views`;
                    document.getElementById('footerViewCount').textContent = data.view_count || 0;
                }
            } catch (err) {
                console.warn('Stats error:', err);
            }
        }

        document.addEventListener('DOMContentLoaded', () => {
            trackView();
            setTimeout(loadStats, 1000);
        });
    </script>
</body>
</html>