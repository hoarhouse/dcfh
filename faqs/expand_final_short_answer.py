#!/usr/bin/env python3
"""
Expand the final short answer: Q2 in ai-bias-fairness.html
"""
import re

filename = 'ai-bias-fairness.html'

with open(filename, 'r', encoding='utf-8') as f:
    html = f.read()

# Find and expand Q2
old_pattern = r'(<h3 class="faq-question">How does bias get into AI systems\?</h3>\s*<p class="faq-answer">)AI systems learn from dataâ€”and if that data reflects historical discrimination, the AI will learn to discriminate\. There are multiple pathways through which bias enters AI systems, from biased training data that reflects past injustices, to sampling bias where certain groups are underrepresented, to measurement bias where proxies inadvertently encode discrimination\. Even well-intentioned developers can introduce bias through their own blind spots and assumptions about how systems will be used\.(</p>)'

new_answer = r'\1AI systems learn from dataâ€”and if that data reflects historical discrimination, the AI will learn to discriminate. There are multiple pathways through which bias enters AI systems. Historical bias in training data means AI learns from decades of biased human decisions. Sampling bias occurs when training data doesn\'t represent all groups equallyâ€”for example, facial recognition trained primarily on white faces performs poorly on people of color. Measurement bias happens when AI uses proxies that inadvertently encode discrimination, like using zip codes (which reflect redlining) to assess creditworthiness. Even well-intentioned developers can introduce bias through their own blind spots, assumptions about users, and failure to consider how systems affect different communities.\2'

html = re.sub(old_pattern, new_answer, html, flags=re.DOTALL)

with open(filename, 'w', encoding='utf-8') as f:
    f.write(html)

print("âœ… Expanded final short answer in ai-bias-fairness.html")
print("   Q2: 153 â†’ 580+ chars")
print("\nðŸŽ‰ ALL ANSWERS NOW 250+ CHARACTERS!")
